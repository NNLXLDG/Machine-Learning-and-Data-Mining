# Python Advanced Techniques for AI Deployment

> æœ¬æ–‡æ¡£é¢å‘åˆšæ¥è§¦ AI æ¨¡å‹éƒ¨ç½²çš„å­¦ç”Ÿï¼Œæ—¨åœ¨é€šè¿‡æ·±å…¥ Python é«˜çº§ç‰¹æ€§ï¼Œå¸®åŠ©ä½ å†™å‡ºé«˜æ•ˆã€å¯ç»´æŠ¤çš„ AI å·¥ç¨‹ä»£ç ã€‚

---

## 1. Python çš„æ‰§è¡Œæ¨¡å‹

### 1.1 Python çš„è¿è¡Œæœºåˆ¶

**CPython è§£é‡Šå™¨å¦‚ä½•æ‰§è¡Œä»£ç **

ä½ çŸ¥é“å—ï¼ŸPython ä»£ç åœ¨æ‰§è¡Œå‰ä¼šç»è¿‡ä»¥ä¸‹æ­¥éª¤ï¼š

1. **æºä»£ç ** â†’ **å­—èŠ‚ç **ï¼ˆç¼–è¯‘ï¼‰
2. **å­—èŠ‚ç ** â†’ **æœºå™¨ç **ï¼ˆè§£é‡Šæ‰§è¡Œï¼‰

```python
import dis

def hello():
    x = 5
    y = 10
    return x + y

# åç¼–è¯‘æŸ¥çœ‹å­—èŠ‚ç 
dis.dis(hello)
```

è¿™å¾ˆé‡è¦ï¼Œå› ä¸ºï¼šå½“ä½ ç”¨ PyTorch DataLoader æ—¶ï¼Œæ¯ä¸ª worker è¿›ç¨‹éƒ½éœ€è¦ç‹¬ç«‹æ‰§è¡Œå­—èŠ‚ç ï¼Œè¿™å°±æ¶‰åŠåˆ°ä¸‹é¢çš„ GIL é—®é¢˜ã€‚

**GILï¼ˆå…¨å±€è§£é‡Šå™¨é”ï¼‰çš„æœ¬è´¨**

CPython ä¸ºäº†ç®€åŒ–å†…å­˜ç®¡ç†ï¼Œç”¨ä¸€æŠŠå…¨å±€é”ï¼ˆGILï¼‰æ¥ä¿æŠ¤å†…å­˜ã€‚è¿™æ„å‘³ç€ï¼š
- **å¤šçº¿ç¨‹ä¸èƒ½çœŸæ­£å¹¶è¡Œæ‰§è¡Œ Python å­—èŠ‚ç **ï¼ˆåªèƒ½è½®æµæ‰§è¡Œï¼‰
- **å¤šè¿›ç¨‹æ‰èƒ½çœŸæ­£å¹¶è¡Œ**ï¼ˆæ¯ä¸ªè¿›ç¨‹æœ‰ç‹¬ç«‹çš„ GILï¼‰

```python
import threading
import time

def cpu_intensive():
    """CPU å¯†é›†å‹ä»»åŠ¡"""
    total = 0
    for i in range(10**8):
        total += i
    return total

# âŒ å¤šçº¿ç¨‹ç‰ˆæœ¬ - åè€Œæ›´æ…¢ï¼ˆå› ä¸º GILï¼‰
start = time.time()
t1 = threading.Thread(target=cpu_intensive)
t2 = threading.Thread(target=cpu_intensive)
t1.start()
t2.start()
t1.join()
t2.join()
print(f"å¤šçº¿ç¨‹è€—æ—¶: {time.time() - start:.2f}s")  # çº¦ 8ç§’

# âœ… å¤šè¿›ç¨‹ç‰ˆæœ¬ - çœŸæ­£å¹¶è¡Œ
from multiprocessing import Process
start = time.time()
p1 = Process(target=cpu_intensive)
p2 = Process(target=cpu_intensive)
p1.start()
p2.start()
p1.join()
p2.join()
print(f"å¤šè¿›ç¨‹è€—æ—¶: {time.time() - start:.2f}s")  # çº¦ 4ç§’
```

**ä¸ºä»€ä¹ˆ AI ä»£ç ä¸­å¸¸å¸¸ç”¨å¤šè¿›ç¨‹è€Œä¸æ˜¯å¤šçº¿ç¨‹ï¼Ÿ**

å› ä¸ºï¼š
- **æ•°æ®åŠ è½½** = CPU å¯†é›†å‹ï¼ˆæ•°æ®å¢å¼ºã€é¢„å¤„ç†éƒ½æ˜¯ CPU æ“ä½œï¼‰
- **å¤šçº¿ç¨‹è¢« GIL é˜»æŒ¡**ï¼Œæ— æ³•çœŸæ­£å¹¶è¡Œ
- **PyTorch DataLoader** é»˜è®¤ç”¨ `num_workers > 0` å°±æ˜¯å¤šè¿›ç¨‹çš„åŸå› 

**ğŸ’¡ å¯¹ AI çš„é‡è¦æ€§**ï¼šç†è§£è¿™ä¸€ç‚¹ï¼Œä½ å°±çŸ¥é“ä¸ºä»€ä¹ˆè®¾ç½® `DataLoader(num_workers=4)` èƒ½çœŸæ­£åŠ é€Ÿæ•°æ®åŠ è½½ã€‚

---

### 1.2 æ·±å…¥ç†è§£å˜é‡ã€ä½œç”¨åŸŸä¸å†…å­˜ç®¡ç†

**Python çš„å¼•ç”¨è®¡æ•°æœºåˆ¶**

Python ç”¨å¼•ç”¨è®¡æ•°æ¥ç®¡ç†å†…å­˜ï¼š
- æ¯ä¸ªå¯¹è±¡éƒ½æœ‰ä¸€ä¸ª `refcount`ï¼ˆå¼•ç”¨è®¡æ•°ï¼‰
- å½“ refcount = 0 æ—¶ï¼Œåƒåœ¾å›æ”¶å™¨ç«‹å³é‡Šæ”¾å†…å­˜

```python
import sys

x = [1, 2, 3]
print(sys.getrefcount(x))  # è‡³å°‘ 2ï¼ˆx çš„å¼•ç”¨ + getrefcount å‚æ•°çš„å¼•ç”¨ï¼‰

y = x  # å¼•ç”¨è®¡æ•° +1
print(sys.getrefcount(x))  # ç°åœ¨æ˜¯ 3

del y  # å¼•ç”¨è®¡æ•° -1
print(sys.getrefcount(x))  # å›åˆ° 2
```

**å±€éƒ¨å˜é‡ vs é—­åŒ…å˜é‡**

```python
def outer():
    captured = [1, 2, 3]  # é—­åŒ…ä¸­è¢«æ•è·çš„å˜é‡
    
    def inner():
        print(captured)  # å¯è®¿é—®å¤–å±‚å˜é‡
        local_var = 99   # ä»…åœ¨ inner å†…æœ‰æ•ˆ
    
    return inner

func = outer()
# captured ä»ç„¶åœ¨å†…å­˜ä¸­ï¼Œå› ä¸ºè¢« inner å¼•ç”¨ï¼ˆé—­åŒ…ï¼‰
```

è¿™åœ¨ AI ä»£ç ä¸­å¾ˆå…³é”®ï¼š
```python
def create_data_loader(data_list):
    """å·¥å‚å‡½æ•°"""
    def load_batch():
        # data_list è¢«æ•è·åœ¨é—­åŒ…ä¸­ï¼Œä¸ä¼šè¢«é‡Šæ”¾
        return data_list[:10]
    return load_batch

loader = create_data_loader([1,2,3,...,1000000])
# å³ä½¿æ•°æ®é›†å¾ˆå¤§ï¼Œåªè¦ loader è¢«å¼•ç”¨ï¼Œdata_list å°±ä¸€ç›´åœ¨å†…å­˜ä¸­
```

**id() ä¸å¯¹è±¡é©»ç•™æœºåˆ¶**

```python
# å°æ•´æ•°é©»ç•™ï¼ˆCPython ä¼˜åŒ–ï¼‰
a = 256
b = 256
print(a is b)  # Trueï¼ˆåŒä¸€å¯¹è±¡ï¼‰

c = 257
d = 257
print(c is d)  # Falseï¼ˆä¸åŒå¯¹è±¡ï¼‰

# å­—ç¬¦ä¸²é©»ç•™
s1 = "hello_world"
s2 = "hello_world"
print(s1 is s2)  # Trueï¼ˆé©»ç•™ï¼‰
```

è¿™çœ‹ä¼¼æ— å…³ï¼Œä½†åœ¨å¤„ç†æ•°æ®å¢å¼ºæ—¶ï¼Œå¦‚æœä½ ä¸å°å¿ƒå¤šæ¬¡å¤åˆ¶äº†æ•°æ®ï¼Œå¼•ç”¨è®¡æ•°å’Œé©»ç•™æœºåˆ¶å¯èƒ½å¯¼è‡´å†…å­˜æ³„æ¼ã€‚

**ğŸ’¡ å¯¹ AI çš„é‡è¦æ€§**ï¼š

é¿å…æ•°æ®å¢å¼º/åŠ è½½æ—¶å‡ºç°éšæ€§å¤åˆ¶ â†’ é™ä½æ˜¾å­˜/å†…å­˜æ¶ˆè€—ã€‚ä¾‹å¦‚ï¼š

```python
# âŒ é”™è¯¯æ–¹å¼ï¼šå¤šæ¬¡å¤åˆ¶æ•°æ®
def bad_augment(image):
    img1 = image.copy()      # å¤šä½™å¤åˆ¶
    img2 = img1.copy()       # åˆå¤åˆ¶äº†
    return img2

# âœ… æ­£ç¡®æ–¹å¼ï¼šåŸåœ°æ“ä½œæˆ–å°‘å¤åˆ¶
import numpy as np
def good_augment(image):
    # ç›´æ¥ä¿®æ”¹ï¼Œå‡å°‘å†…å­˜å¼€é”€
    image = image.astype(np.float32) / 255.0
    return image
```


---

## 2. è¿­ä»£å™¨ä¸ç”Ÿæˆå™¨ï¼ˆæ•°æ®åŠ è½½çš„åŸºç¡€ï¼‰

### 2.1 è¿­ä»£å™¨åè®®

ä»»ä½•å®ç°äº† `__iter__()` å’Œ `__next__()` çš„å¯¹è±¡éƒ½æ˜¯**è¿­ä»£å™¨**ã€‚

```python
# è‡ªå®šä¹‰è¿­ä»£å™¨
class CountUp:
    def __init__(self, max):
        self.max = max
        self.current = 0
    
    def __iter__(self):
        return self  # è¿”å›è‡ªå·±
    
    def __next__(self):
        if self.current < self.max:
            self.current += 1
            return self.current
        else:
            raise StopIteration  # è¿­ä»£ç»“æŸ

# ä½¿ç”¨
for num in CountUp(3):
    print(num)  # è¾“å‡º 1, 2, 3
```

**å¯è¿­ä»£å¯¹è±¡ vs è¿­ä»£å™¨å¯¹è±¡**

- **å¯è¿­ä»£å¯¹è±¡**ï¼šå®ç°äº† `__iter__()` çš„å¯¹è±¡ï¼ˆå¦‚åˆ—è¡¨ã€å­—ç¬¦ä¸²ã€é›†åˆï¼‰
- **è¿­ä»£å™¨å¯¹è±¡**ï¼šå®ç°äº† `__iter__()` å’Œ `__next__()` çš„å¯¹è±¡

```python
# åˆ—è¡¨æ˜¯å¯è¿­ä»£çš„ï¼Œä½†ä¸æ˜¯è¿­ä»£å™¨
lst = [1, 2, 3]
print(hasattr(lst, '__iter__'))  # True
print(hasattr(lst, '__next__'))  # False

# iter() å°†å¯è¿­ä»£å¯¹è±¡è½¬ä¸ºè¿­ä»£å™¨
iterator = iter(lst)
print(hasattr(iterator, '__next__'))  # True
print(next(iterator))  # 1
print(next(iterator))  # 2
```

### 2.2 ç”Ÿæˆå™¨åŸºç¡€ï¼šä»åˆ—è¡¨åˆ°æµ

**yield çš„æ¥å†å’Œæœ¬è´¨**

åœ¨ Python 2.2 ä¹‹å‰ï¼Œå¦‚æœä½ è¦éå†å¤§æ•°æ®é›†ï¼Œå¿…é¡»ä¸€æ¬¡æ€§åŠ è½½åˆ°å†…å­˜ä¸­ã€‚è¿™å¯¹ AI æ¥è¯´æ˜¯ç¾éš¾æ€§çš„â€”â€”æƒ³è±¡ ImageNetï¼ˆæ•°ç™¾GBï¼‰ï¼Œä½ æ— æ³•å…¨éƒ¨åŠ è½½ã€‚

ç”Ÿæˆå™¨é€šè¿‡ `yield` æä¾›äº†è§£å†³æ–¹æ¡ˆï¼š**å‡½æ•°å¯ä»¥åœ¨ä¸­é€”æš‚åœï¼Œä¿å­˜çŠ¶æ€ï¼Œç­‰å¾…ä¸‹ä¸€æ¬¡å”¤é†’**ã€‚è¿™ç§"å»¶è¿Ÿè®¡ç®—"æ€æƒ³æ˜¯ç°ä»£æ•°æ®å¤„ç†çš„åŸºç¡€ã€‚

å…·ä½“å·¥ä½œåŸç†ï¼š
- é¦–æ¬¡ `next()`ï¼šå‡½æ•°æ‰§è¡Œè‡³ `yield`ï¼Œè¿”å›å€¼ï¼Œç„¶åæš‚åœ
- å†æ¬¡ `next()`ï¼šä»æš‚åœå¤„ç»§ç»­æ‰§è¡Œï¼Œç›´åˆ°ä¸‹ä¸€ä¸ª `yield`
- å‡½æ•°è¿”å›æˆ–æŠ›å‡º `StopIteration`ï¼šè¿­ä»£ç»“æŸ

è¿™ä½¿å¾—ç”Ÿæˆå™¨æ˜¯**æœ‰çŠ¶æ€çš„è¿­ä»£å™¨**â€”â€”å®ƒè®°ä½ä¸Šæ¬¡æ‰§è¡Œåˆ°å“ªé‡Œã€‚

```python
def simple_generator():
    print("å¼€å§‹")
    yield 1
    print("ç»§ç»­")
    yield 2
    print("ç»“æŸ")
    yield 3

gen = simple_generator()
print(next(gen))  # "å¼€å§‹", è¿”å› 1
print(next(gen))  # "ç»§ç»­", è¿”å› 2
print(next(gen))  # "ç»“æŸ", è¿”å› 3
```

**ä¸ºä»€ä¹ˆç”Ÿæˆå™¨å¯¹ AI è‡³å…³é‡è¦ï¼Ÿ**

å¯¹æ¯”ä¸¤ç§æ–¹å¼ï¼š
```python
# æ–¹å¼ 1ï¼šåˆ—è¡¨ - ä¸€æ¬¡æ€§åˆ›å»º
big_list = [x**2 for x in range(10**6)]  # ç«‹å³å ç”¨ ~40MB

# æ–¹å¼ 2ï¼šç”Ÿæˆå™¨ - æŒ‰éœ€è®¡ç®—
big_gen = (x**2 for x in range(10**6))  # åªå ç”¨å‡  KB
```

åœ¨è®­ç»ƒä¸­ï¼Œç”Ÿæˆå™¨å…è®¸ä½ ï¼š
- å¤„ç†è¶…å¤§æ•°æ®é›†ï¼ˆåªåœ¨å†…å­˜ä¸­æ”¾ä¸€å°æ‰¹ï¼‰
- å®æ—¶æ•°æ®å¢å¼ºï¼ˆæ¯ä¸ª epoch çœ‹åˆ°ä¸åŒå¢å¼ºï¼‰
- æ— é™æ•°æ®æµï¼ˆOnline Learningï¼‰

PyTorch çš„ `DataLoader` å’Œ `IterableDataset` éƒ½åŸºäºç”Ÿæˆå™¨æ€æƒ³ã€‚

### 2.3 é¢å‘ AI çš„ç”Ÿæˆå™¨åº”ç”¨åœºæ™¯

**è‡ªå®šä¹‰æ•°æ®é›†åŠ è½½å™¨**

åœ¨ PyTorch ä¸­ï¼Œç»§æ‰¿ `IterableDataset` å¹¶å®ç° `__iter__()` æ–¹æ³•ã€‚å®ƒè¿”å›ä¸€ä¸ªç”Ÿæˆå™¨ï¼Œæ¯” `Map-style Dataset` æ›´çµæ´»â€”â€”å¯ä»¥åŠ¨æ€å†³å®šç”Ÿæˆä»€ä¹ˆæ•°æ®ï¼Œæ— éœ€é¢„å…ˆå®šä¹‰å¤§å°ã€‚

```python
class CustomDataset:
    def __iter__(self):
        for i in range(1000):
            yield (f"sample_{i}", i)
```

ä¼˜åŠ¿ï¼š
- **å†…å­˜é«˜æ•ˆ**ï¼šä¸éœ€è¦é¢„å…ˆåŠ è½½æ‰€æœ‰æ•°æ®
- **çµæ´»æ€§**ï¼šæ ¹æ®éœ€è¦åŠ¨æ€ç”Ÿæˆï¼ˆæ•°æ®å¢å¼ºã€é‡‡æ ·ï¼‰
- **æ— é™æµ**ï¼šå¯ä»¥æ— é™ yield

**æµå¼è¯»å–å¤§æ ‡æ³¨æ–‡ä»¶ï¼ˆå¦‚ COCO annotationsï¼‰**

COCO annotations å¯èƒ½æ•°GB å¤§ã€‚ç”¨åˆ—è¡¨ä¸€æ¬¡åŠ è½½ä¼š OOMã€‚ä½†ç”Ÿæˆå™¨å¯é€è¡Œè¯»å–ï¼Œ**æ— è®ºæ–‡ä»¶å¤šå¤§ï¼Œå†…å­˜ä¸­åŒæ—¶åªæœ‰ä¸€ä¸ªæ‰¹æ¬¡**ï¼š

```python
def read_annotations_stream(filepath, batch_size=32):
    import json
    batch = []
    with open(filepath) as f:
        for line in f:
            batch.append(json.loads(line))
            if len(batch) == batch_size:
                yield batch
                batch = []
    if batch:
        yield batch
```

è¿™æ¯” `json.load(open(file))` ä¸€æ¬¡æ€§åŠ è½½èŠ‚çœ 95% ä»¥ä¸Šå†…å­˜ã€‚

**æ•°æ®å¢å¼ºä¸åœ¨çº¿å­¦ä¹ **

æœ‰äº›åœºæ™¯éœ€è¦å®æ—¶ç”Ÿæˆè®­ç»ƒæ ·æœ¬ï¼ˆå¯¹æŠ—è®­ç»ƒã€åœ¨çº¿å­¦ä¹ ï¼‰ã€‚ç”Ÿæˆå™¨å®Œç¾é€‚åº”ï¼š

```python
def online_augment_generator(base_samples):
    while True:  # æ— é™å¾ªç¯
        for sample in base_samples:
            augmented = apply_random_augmentation(sample)
            yield augmented
```

è¿™è®©æ¨¡å‹æ¯ä¸ª epoch çœ‹åˆ°ä¸åŒå¢å¼ºç‰ˆæœ¬ï¼Œæå‡æ³›åŒ–ã€‚PyTorch DataLoader + num_workers å°±æ˜¯åœ¨åå°å¤šè¿›ç¨‹è¿è¡Œè¿™æ ·çš„ç”Ÿæˆå™¨ã€‚

**ğŸ’¡ ä¸ºä»€ä¹ˆç”Ÿæˆå™¨æ˜¯ AI æ•°æ®å¤„ç†çš„æ ¸å¿ƒ**

ç°ä»£æ¡†æ¶ï¼ˆPyTorchã€TensorFlowï¼‰çš„æ•°æ®åŠ è½½æœºåˆ¶éƒ½å›´ç»•ç”Ÿæˆå™¨è®¾è®¡ï¼š
1. **å†…å­˜æ•ˆç‡**ï¼šæ— éœ€ä¸€æ¬¡æ€§åŠ è½½
2. **CPU é¢„åŠ è½½**ï¼šåå°ç”Ÿæˆä¸‹ä¸€æ‰¹ï¼ŒGPU è®­ç»ƒå½“å‰æ‰¹ï¼ŒCPU-GPU å¹¶è¡Œ
3. **çµæ´»æ€§**ï¼šæ”¯æŒåŠ¨æ€å¢å¼ºã€é‡‡æ ·ã€åœ¨çº¿å­¦ä¹ 
4. **å¯æ‰©å±•**ï¼šå¤„ç† TB çº§æ•°æ®é›†

**ğŸ’¡ å¯¹ AI çš„é‡è¦æ€§**ï¼š

å¤§å‹æ•°æ®é›† & æ•°æ®æµå¤„ç†çš„æ ¸å¿ƒæŠ€èƒ½ã€‚ä¾‹å¦‚åœ¨å›¾åƒåˆ†ç±»ä¸­ï¼š

```python
# PyTorch Dataset çš„æ ¸å¿ƒå°±æ˜¯è¿­ä»£å™¨
import torch.utils.data as data

class CustomImageDataset(data.Dataset):
    def __init__(self, image_paths, labels, transform=None):
        self.image_paths = image_paths
        self.labels = labels
        self.transform = transform
    
    def __len__(self):
        return len(self.image_paths)
    
    def __getitem__(self, idx):
        # è¿™æ˜¯ä¸€ä¸ª "å»¶è¿ŸåŠ è½½" æ¨¡å¼
        # åªåœ¨éœ€è¦æ—¶åŠ è½½å›¾åƒï¼Œè€Œä¸æ˜¯å…¨éƒ¨é¢„åŠ è½½
        image = load_image(self.image_paths[idx])
        if self.transform:
            image = self.transform(image)
        return image, self.labels[idx]
```

---

## 3. è£…é¥°å™¨ï¼šå‡½æ•°çš„å¢å¼ºå·¥å‚

è£…é¥°å™¨æ˜¯ Python æœ€å¼ºå¤§çš„ç‰¹æ€§ä¹‹ä¸€ï¼Œä½†ä¹Ÿæ˜¯æœ€å®¹æ˜“è¢«è¯¯ç”¨çš„ã€‚åœ¨ AI å·¥ç¨‹ä¸­ï¼Œè£…é¥°å™¨ç”¨äºè®°å½•è®­ç»ƒæ—¥å¿—ã€è‡ªåŠ¨é‡è¯•ã€æ€§èƒ½ç›‘æ§ç­‰ã€‚æŒæ¡å®ƒï¼Œèƒ½è®©ä½ çš„ä»£ç æ›´ç®€æ´ã€å¯ç»´æŠ¤ã€‚

### 3.1 è£…é¥°å™¨çš„æ ¸å¿ƒæ€æƒ³

**æ¥å†ï¼šå‡½æ•°ä½œä¸ºä¸€ç­‰å¯¹è±¡**

Python ä¸­å‡½æ•°æ˜¯ä¸€ç­‰å¯¹è±¡ï¼ˆFirst-class objectï¼‰ï¼Œæ„å‘³ç€å‡½æ•°å¯ä»¥åƒæ•°æ®ä¸€æ ·è¢«èµ‹å€¼ã€ä¼ é€’ã€è¿”å›ã€‚è¿™æ˜¯è£…é¥°å™¨çš„åŸºç¡€ï¼š

```python
def greet(name):
    return f"Hello, {name}!"

say_hello = greet          # èµ‹å€¼
result = apply_func(greet) # ä½œä¸ºå‚æ•°ä¼ é€’
```

**é—­åŒ…ä¸ *args / **kwargs**

è£…é¥°å™¨çš„æŠ€æœ¯åŸºç¡€æ˜¯**é—­åŒ…**ï¼ˆclosureï¼‰â€”â€”ä¸€ä¸ªå‡½æ•°"è®°ä½"å®ƒå¤–å±‚ä½œç”¨åŸŸçš„å˜é‡ã€‚å¦å¤–ï¼Œ`*args` å’Œ `**kwargs` å…è®¸è£…é¥°å™¨æ¥å—ä»»æ„å‚æ•°çš„å‡½æ•°ï¼š

```python
def multiplier(factor):        # è¿”å›ä¸€ä¸ª"è®°ä½" factor çš„å‡½æ•°
    def multiply(x):
        return x * factor
    return multiply

times_3 = multiplier(3)
print(times_3(10))  # 30
```

`*args` æ¥æ”¶ä»»æ„ä½ç½®å‚æ•°ï¼Œ`**kwargs` æ¥æ”¶ä»»æ„å…³é”®å­—å‚æ•°ã€‚è¿™è®©è£…é¥°å™¨èƒ½é€‚ç”¨äºä»»ä½•å‡½æ•°ç­¾åã€‚

**æ— å‚æ•°è£…é¥°å™¨ï¼šæœ€ç®€å•çš„å½¢å¼**

è£…é¥°å™¨æœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ªå‡½æ•°ï¼Œæ¥å—å¦ä¸€ä¸ªå‡½æ•°ï¼Œè¿”å›ä¸€ä¸ªå¢å¼ºç‰ˆçš„å‡½æ•°ï¼š

```python
def timer_decorator(func):
    def wrapper(*args, **kwargs):
        import time
        start = time.time()
        result = func(*args, **kwargs)
        print(f"{func.__name__} è€—æ—¶: {time.time() - start:.4f}s")
        return result
    return wrapper

@timer_decorator
def train_epoch():
    import time
    time.sleep(1)
    return "å®Œæˆ"

train_epoch()  # æ‰“å°è€—æ—¶ï¼Œç„¶åè¿”å›ç»“æœ
```

`@timer_decorator` è¿™ä¸ªè¯­æ³•ç³–ç­‰ä»·äº `train_epoch = timer_decorator(train_epoch)`ã€‚

**æœ‰å‚æ•°è£…é¥°å™¨ï¼šå¤šå±‚åµŒå¥—**

æœ‰æ—¶ä½ éœ€è¦ç»™è£…é¥°å™¨ä¼ å‚ã€‚è¿™éœ€è¦å¤šä¸€å±‚å‡½æ•°åµŒå¥—ï¼š

```python
def repeat_decorator(times):     # ç¬¬ä¸€å±‚ï¼šè£…é¥°å™¨å·¥å‚
    def decorator(func):         # ç¬¬äºŒå±‚ï¼šè£…é¥°å™¨
        def wrapper(*args, **kwargs):  # ç¬¬ä¸‰å±‚ï¼šåŒ…è£…å™¨
            for _ in range(times):
                func(*args, **kwargs)
        return wrapper
    return decorator

@repeat_decorator(times=3)
def predict():
    print("é¢„æµ‹ä¸­...")

predict()  # æ‰“å°ä¸‰é"é¢„æµ‹ä¸­..."
```

ç†è§£è¿™ä¸‰å±‚åµŒå¥—å¾ˆå…³é”®â€”â€”å®ƒå…è®¸ä½ è‡ªå®šä¹‰è£…é¥°å™¨çš„è¡Œä¸ºã€‚

### 3.2 è£…é¥°å™¨çš„å·¥ç¨‹å®è·µ

**functools.wrapsï¼šä¿æŒå…ƒä¿¡æ¯**

å½“ä½ è£…é¥°ä¸€ä¸ªå‡½æ•°æ—¶ï¼Œè¢«åŒ…è£…å‡½æ•°çš„ `__name__`ã€`__doc__` ç­‰å…ƒä¿¡æ¯ä¼šä¸¢å¤±ï¼Œå˜æˆ `wrapper`ã€‚è¿™åœ¨è°ƒè¯•æ—¶å¾ˆå›°æ‰°ã€‚`functools.wraps` è§£å†³äº†è¿™ä¸ªé—®é¢˜ï¼š

```python
from functools import wraps

def good_decorator(func):
    @wraps(func)  # å¤åˆ¶åŸå‡½æ•°çš„å…ƒä¿¡æ¯
    def wrapper(*args, **kwargs):
        return func(*args, **kwargs)
    return wrapper

@good_decorator
def important_function():
    """è¿™æ˜¯é‡è¦å‡½æ•°"""
    pass

print(important_function.__name__)  # ä¿ç•™åŸå
print(important_function.__doc__)   # ä¿ç•™æ–‡æ¡£
```

**ç¼“å­˜è£…é¥°å™¨ï¼šé¿å…é‡å¤è®¡ç®—**

å¦‚æœæŸä¸ªå‡½æ•°åœ¨ç›¸åŒè¾“å…¥ä¸‹æ€»æ˜¯è¿”å›ç›¸åŒç»“æœï¼Œå¯ä»¥ç¼“å­˜ç»“æœï¼š

```python
from functools import lru_cache

@lru_cache(maxsize=128)
def expensive_function(n):
    import time
    time.sleep(1)  # æ¨¡æ‹Ÿæ˜‚è´µè®¡ç®—
    return n * n

result1 = expensive_function(5)  # è€—æ—¶ 1 ç§’ï¼Œè®¡ç®—å¹¶ç¼“å­˜
result2 = expensive_function(5)  # ç«‹å³è¿”å›ï¼ˆä»ç¼“å­˜ï¼‰
```

åœ¨ AI æ¨ç†ä¸­ï¼Œè¿™å¾ˆæœ‰ç”¨â€”â€”é¿å…é‡å¤æ¨ç†ç›¸åŒè¾“å…¥ã€‚

### 3.3 AI å·¥ç¨‹ä¸­çš„è£…é¥°å™¨åº”ç”¨

**è®­ç»ƒè¿‡ç¨‹çš„è®¡æ—¶ä¸ç›‘æ§**

åœ¨æ·±åº¦å­¦ä¹ ä¸­ï¼Œä½ éœ€è¦ç›‘æ§å„éƒ¨åˆ†çš„è€—æ—¶ï¼ˆåŠ è½½æ•°æ®ã€å‰å‘ä¼ æ’­ã€åå‘ä¼ æ’­ç­‰ï¼‰ã€‚è£…é¥°å™¨å¯ä»¥è‡ªåŠ¨åŒ–è¿™ä¸ªè¿‡ç¨‹ï¼Œè€Œæ— éœ€åœ¨å‡½æ•°å†…éƒ¨æ•£å¸ƒè®¡æ—¶ä»£ç ï¼š

```python
def training_timer(func):
    from functools import wraps
    import time
    
    @wraps(func)
    def wrapper(*args, **kwargs):
        start = time.time()
        result = func(*args, **kwargs)
        elapsed = time.time() - start
        print(f"[{func.__name__}] è€—æ—¶: {elapsed:.3f}s")
        return result
    return wrapper

@training_timer
def load_batch(dataloader, batch_idx):
    # åŠ è½½æ•°æ®é€»è¾‘
    return batch

@training_timer
def train_step(model, batch):
    # è®­ç»ƒé€»è¾‘
    return loss
```

è¿™è®©ä½ å¯ä»¥è½»æ¾æ·»åŠ /ç§»é™¤ç›‘æ§ï¼Œè€Œæ— éœ€ä¿®æ”¹å‡½æ•°æœ¬èº«ã€‚

**è‡ªåŠ¨é‡è¯•è£…é¥°å™¨ï¼šå®¹é”™èƒ½åŠ›**

ç½‘ç»œè¯·æ±‚ã€æ•°æ®åŠ è½½ç­‰æ“ä½œå¯èƒ½å¤±è´¥ã€‚è£…é¥°å™¨å¯ä»¥è‡ªåŠ¨é‡è¯•ï¼š

```python
def retry(max_attempts=3, delay=1):
    def decorator(func):
        from functools import wraps
        import time
        
        @wraps(func)
        def wrapper(*args, **kwargs):
            for attempt in range(1, max_attempts + 1):
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    if attempt == max_attempts:
                        raise
                    print(f"Attempt {attempt} failed, retrying in {delay}s...")
                    time.sleep(delay)
        return wrapper
    return decorator

@retry(max_attempts=3, delay=2)
def download_dataset(url):
    # ä¸‹è½½é€»è¾‘ï¼Œå¯èƒ½å¤±è´¥
    import requests
    return requests.get(url).content
```

**æ—¥å¿—è®°å½•è£…é¥°å™¨**

è‡ªåŠ¨è®°å½•å‡½æ•°è°ƒç”¨ã€å‚æ•°å’Œè¿”å›å€¼ï¼Œå¯¹è°ƒè¯•å¾ˆæœ‰å¸®åŠ©ï¼š

```python
def log_execution(func):
    from functools import wraps
    import logging
    
    @wraps(func)
    def wrapper(*args, **kwargs):
        logging.info(f"Calling {func.__name__} with args={args}, kwargs={kwargs}")
        result = func(*args, **kwargs)
        logging.info(f"{func.__name__} returned {type(result)}")
        return result
    return wrapper

@log_execution
def predict(model, image):
    return model(image)
```

**ğŸ’¡ è£…é¥°å™¨çš„æœ€å¤§ä¼˜åŠ¿**

è£…é¥°å™¨è®©ä½ åœ¨ä¸ä¿®æ”¹åŸå‡½æ•°ä»£ç çš„æƒ…å†µä¸‹ï¼Œä¸ºå…¶æ·»åŠ æ–°åŠŸèƒ½ã€‚åœ¨å¤§å‹ AI é¡¹ç›®ä¸­ï¼Œè¿™æ„å‘³ç€ï¼š
- ä»£ç å¤ç”¨ï¼šä¸€æ¬¡å®šä¹‰ï¼Œåˆ°å¤„ä½¿ç”¨
- å…³æ³¨ç‚¹åˆ†ç¦»ï¼šåˆ†ç¦»ä¸šåŠ¡é€»è¾‘å’Œç›‘æ§/æ—¥å¿—
- æ˜“ç»´æŠ¤ï¼šä¿®æ”¹è£…é¥°å™¨æ—¶ï¼Œæ‰€æœ‰ä½¿ç”¨å®ƒçš„å‡½æ•°è‡ªåŠ¨æ›´æ–°

---

## 4. å¹¶è¡Œä¸å¹¶å‘ï¼šåŠ é€Ÿæ•°æ®å¤„ç†

**è®­ç»ƒè®¡æ—¶å™¨ decorator**

```python
from functools import wraps
import time

def training_timer(func):
    """è®°å½•è®­ç»ƒè¿‡ç¨‹ä¸­å„éƒ¨åˆ†çš„è€—æ—¶"""
    @wraps(func)
    def wrapper(*args, **kwargs):
        print(f"ã€{func.__name__}ã€‘å¼€å§‹æ‰§è¡Œ...")
        start = time.time()
        result = func(*args, **kwargs)
        elapsed = time.time() - start
        print(f"ã€{func.__name__}ã€‘å®Œæˆï¼è€—æ—¶ {elapsed:.2f}s")
        return result
    return wrapper

@training_timer
def train_epoch():
    import time
    time.sleep(0.5)
    return "epochå®Œæˆ"

train_epoch()
# ã€train_epochã€‘å¼€å§‹æ‰§è¡Œ...
# ã€train_epochã€‘å®Œæˆï¼è€—æ—¶ 0.50s
```

**è‡ªåŠ¨æ—¥å¿—è®°å½• decorator**

```python
import logging
from functools import wraps

def auto_logger(func):
    """è‡ªåŠ¨è®°å½•å‡½æ•°çš„è¾“å…¥å’Œè¾“å‡º"""
    @wraps(func)
    def wrapper(*args, **kwargs):
        logging.info(f"è°ƒç”¨ {func.__name__}ï¼Œå‚æ•°: {args}, {kwargs}")
        try:
            result = func(*args, **kwargs)
            logging.info(f"{func.__name__} è¿”å›: {result}")
            return result
        except Exception as e:
            logging.error(f"{func.__name__} å¼‚å¸¸: {e}")
            raise
    return wrapper

@auto_logger
def forward_pass(input_tensor):
    return "æ¨¡å‹è¾“å‡º"

forward_pass(torch.randn(1, 3, 224, 224))
```

**è‡ªåŠ¨é‡è¯•ï¼ˆå®¹é”™è®­ç»ƒä»»åŠ¡ï¼‰decorator**

```python
from functools import wraps
import time

def retry(max_attempts=3, delay=1):
    """å¤±è´¥åè‡ªåŠ¨é‡è¯•çš„è£…é¥°å™¨"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            for attempt in range(max_attempts):
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    if attempt == max_attempts - 1:
                        raise
                    print(f"ç¬¬ {attempt+1} æ¬¡å¤±è´¥: {e}ï¼Œ{delay}ç§’åé‡è¯•...")
                    time.sleep(delay)
        return wrapper
    return decorator

@retry(max_attempts=3, delay=2)
def download_model():
    """ä¸‹è½½æ¨¡å‹æƒé‡"""
    import random
    if random.random() < 0.7:
        raise ConnectionError("ç½‘ç»œé”™è¯¯")
    return "æ¨¡å‹åŠ è½½æˆåŠŸ"

# ä¼šè‡ªåŠ¨é‡è¯•ï¼Œç›´åˆ°æˆåŠŸæˆ–è¾¾åˆ°æœ€å¤§æ¬¡æ•°
```

**ç¼“å­˜æ¨¡å‹æ¨ç†ç»“æœï¼ˆé¿å…é‡å¤è®¡ç®—ï¼‰**

```python
from functools import lru_cache

@lru_cache(maxsize=1000)
def model_inference(input_hash):
    """ç¼“å­˜æ¨ç†ç»“æœï¼Œé¿å…é‡å¤è®¡ç®—"""
    # input_hash æ˜¯è¾“å…¥çš„å“ˆå¸Œå€¼
    # è¿™æ ·å¯ä»¥é¿å…å¯¹åŒä¸€è¾“å…¥çš„é‡å¤æ¨ç†
    return model(input_hash)

# ä½¿ç”¨ç¤ºä¾‹
image_hash = hash(str(image_array.tostring()))
result = model_inference(image_hash)  # é¦–æ¬¡è®¡ç®—
result = model_inference(image_hash)  # ç›´æ¥ä»ç¼“å­˜è¿”å›
```

**ğŸ’¡ å¯¹ AI çš„é‡è¦æ€§**ï¼š

è®­ç»ƒæµç¨‹å¯æ§ã€è‡ªåŠ¨åŒ–ã€æ¨¡å—åŒ–å†™æ³•çš„åŸºç¡€ã€‚è£…é¥°å™¨è®©ä½ çš„ä»£ç æ›´ç®€æ´ã€æ›´æ˜“ç»´æŠ¤ã€‚





---

## 4. å¹¶è¡Œ / å¹¶å‘ï¼ˆAI æ•°æ®å¤„ç†çš„æ ¸å¿ƒæŠ€èƒ½ï¼‰

### 4.1 Threadingï¼ˆå¤šçº¿ç¨‹ï¼‰

å¤šçº¿ç¨‹é€‚åˆ **IO å¯†é›†å‹** ä»»åŠ¡ï¼ˆå¦‚ç½‘ç»œè¯·æ±‚ã€æ–‡ä»¶ IOï¼‰ã€‚ä½†ç”±äº GILï¼Œä¸é€‚åˆ CPU å¯†é›†å‹ä»»åŠ¡ã€‚

```python
import threading
import time

def io_intensive_task(task_id):
    """æ¨¡æ‹Ÿ IO æ“ä½œï¼ˆå¦‚ä¸‹è½½æ•°æ®é›†ï¼‰"""
    print(f"ä»»åŠ¡ {task_id} å¼€å§‹")
    time.sleep(2)  # æ¨¡æ‹Ÿç½‘ç»œå»¶è¿Ÿ
    print(f"ä»»åŠ¡ {task_id} å®Œæˆ")

# å•çº¿ç¨‹ï¼š2ä¸ªä»»åŠ¡è€—æ—¶ 4ç§’
start = time.time()
io_intensive_task(1)
io_intensive_task(2)
print(f"å•çº¿ç¨‹è€—æ—¶: {time.time() - start:.2f}s")  # 4ç§’

# å¤šçº¿ç¨‹ï¼š2ä¸ªä»»åŠ¡è€—æ—¶ 2ç§’ï¼ˆçœŸæ­£å¹¶å‘ï¼‰
start = time.time()
t1 = threading.Thread(target=io_intensive_task, args=(1,))
t2 = threading.Thread(target=io_intensive_task, args=(2,))
t1.start()
t2.start()
t1.join()  # ç­‰å¾…çº¿ç¨‹å®Œæˆ
t2.join()
print(f"å¤šçº¿ç¨‹è€—æ—¶: {time.time() - start:.2f}s")  # 2ç§’
```

### 4.2 Multiprocessingï¼ˆå¤šè¿›ç¨‹ï¼‰

å¤šè¿›ç¨‹çªç ´ GIL é™åˆ¶ï¼Œé€‚åˆ **CPU å¯†é›†å‹** ä»»åŠ¡ã€‚æ¯ä¸ªè¿›ç¨‹æœ‰ç‹¬ç«‹çš„è§£é‡Šå™¨å’Œå†…å­˜ã€‚

```python
from multiprocessing import Process, Pool
import time

def cpu_intensive_task(n):
    """CPU å¯†é›†å‹ä»»åŠ¡"""
    total = sum(i*i for i in range(n))
    return total

# å•è¿›ç¨‹ï¼šè€—æ—¶çº¦ 8ç§’
start = time.time()
cpu_intensive_task(10**8)
cpu_intensive_task(10**8)
print(f"å•è¿›ç¨‹è€—æ—¶: {time.time() - start:.2f}s")  # 8ç§’

# å¤šè¿›ç¨‹ï¼šè€—æ—¶çº¦ 4ç§’ï¼ˆçœŸæ­£å¹¶è¡Œï¼‰
start = time.time()
p1 = Process(target=cpu_intensive_task, args=(10**8,))
p2 = Process(target=cpu_intensive_task, args=(10**8,))
p1.start()
p2.start()
p1.join()
p2.join()
print(f"å¤šè¿›ç¨‹è€—æ—¶: {time.time() - start:.2f}s")  # 4ç§’
```

**è¿›ç¨‹æ± ï¼ˆPoolï¼‰**

```python
from multiprocessing import Pool

def square(x):
    return x * x

# ä½¿ç”¨è¿›ç¨‹æ± æ‰¹é‡å¤„ç†
with Pool(4) as pool:
    # map ç›¸å½“äºå†…ç½® mapï¼Œä½†åˆ†å¸ƒåœ¨ 4 ä¸ªè¿›ç¨‹ä¸Š
    results = pool.map(square, range(100))

print(results[:10])  # [0, 1, 4, 9, 16, 25, 36, 49, 64, 81]
```

**å…±äº«å†…å­˜ä¸æ•°æ®å¤åˆ¶**

```python
from multiprocessing import Process, Queue
import numpy as np

def worker(queue, data):
    """å­è¿›ç¨‹æ¥æ”¶æ•°æ®"""
    # âš ï¸ data è¢«å¤åˆ¶åˆ°å­è¿›ç¨‹ï¼è¿™å¾ˆè€—æ—¶
    processed = data * 2
    queue.put(processed)

# ç”¨é˜Ÿåˆ—ï¼ˆQueueï¼‰ä¼ é€’æ•°æ®
q = Queue()
large_data = np.random.randn(1000, 1000)
p = Process(target=worker, args=(q, large_data))
p.start()
result = q.get()  # ä»é˜Ÿåˆ—è·å–ç»“æœ
p.join()
```

ğŸ‘‰ **ä¸ºä»€ä¹ˆ PyTorch DataLoader é»˜è®¤ç”¨å¤šè¿›ç¨‹ï¼Ÿ**

å› ä¸ºï¼š
1. **æ•°æ®åŠ è½½ = CPU å¯†é›†å‹**ï¼ˆå›¾åƒè§£ç ã€æ•°æ®å¢å¼ºéƒ½å¾ˆè€— CPUï¼‰
2. **å¤šçº¿ç¨‹è¢« GIL å¡ä½**ï¼Œæ— æ³•çœŸæ­£å¹¶è¡Œ
3. **å¤šè¿›ç¨‹èƒ½çœŸæ­£å¹¶è¡Œ**ï¼Œå……åˆ†åˆ©ç”¨å¤šæ ¸ CPU

```python
# PyTorch DataLoader å†…éƒ¨ä½¿ç”¨å¤šè¿›ç¨‹
from torch.utils.data import DataLoader, TensorDataset
import torch

dataset = TensorDataset(torch.randn(1000, 3, 224, 224))
# num_workers=4 æ„å‘³ç€ 4 ä¸ªç‹¬ç«‹è¿›ç¨‹åŠ è½½æ•°æ®
loader = DataLoader(dataset, batch_size=32, num_workers=4)

for batch in loader:
    # èƒŒåï¼š4 ä¸ªè¿›ç¨‹åŒæ—¶åŠ è½½å’Œé¢„å¤„ç†æ•°æ®
    pass
```

### 4.3 concurrent.futuresï¼ˆé«˜çº§å¹¶è¡Œ APIï¼‰

æä¾›æ›´ç®€æ´çš„æ¥å£æ¥ç®¡ç†çº¿ç¨‹å’Œè¿›ç¨‹æ± ã€‚

```python
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
import time

def task(n):
    time.sleep(1)
    return n * n

# å¤šçº¿ç¨‹æ± 
with ThreadPoolExecutor(max_workers=4) as executor:
    # submit æäº¤å•ä¸ªä»»åŠ¡
    future = executor.submit(task, 5)
    result = future.result()  # ç­‰å¾…ç»“æœ
    print(f"ç»“æœ: {result}")

# è¿›ç¨‹æ±  + map æ‰¹é‡å¤„ç†
with ProcessPoolExecutor(max_workers=4) as executor:
    results = list(executor.map(task, range(10)))
    print(results)

# Future å¯¹è±¡ç”¨äºå¼‚æ­¥ç¼–ç¨‹
futures = []
with ThreadPoolExecutor(max_workers=4) as executor:
    for i in range(10):
        future = executor.submit(task, i)
        futures.append(future)

# ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
for future in futures:
    print(future.result())
```

### 4.4 Asyncioï¼ˆåç¨‹ï¼‰

```python
import asyncio

async def async_task(n):
    """å¼‚æ­¥å‡½æ•°"""
    print(f"ä»»åŠ¡ {n} å¼€å§‹")
    await asyncio.sleep(1)  # éé˜»å¡ç­‰å¾…
    print(f"ä»»åŠ¡ {n} å®Œæˆ")
    return n * n

# è¿è¡Œåç¨‹
async def main():
    # å¹¶å‘è¿è¡Œå¤šä¸ªåç¨‹
    tasks = [async_task(i) for i in range(5)]
    results = await asyncio.gather(*tasks)
    return results

results = asyncio.run(main())
print(results)
```

**ğŸ’¡ å¯¹ AI çš„é‡è¦æ€§**ï¼š

å¼‚æ­¥ç¼–ç¨‹é€‚åˆ **IO å¯†é›†ä¸”éœ€è¦é«˜åå** çš„åœºæ™¯ï¼ˆå¦‚å¼‚æ­¥æ•°æ®é¢„å¤„ç†ã€å¼‚æ­¥æ¨ç†æœåŠ¡ï¼‰ã€‚

---

## 5. æ€§èƒ½ä¼˜åŒ–ï¼ˆAI å·¥ç¨‹éå¸¸å…³é”®ï¼‰

### 5.1 å†…å­˜ä¼˜åŒ–

**æ·±æ‹·è´ vs æµ…æ‹·è´**

```python
import copy

# æµ…æ‹·è´ï¼šåªå¤åˆ¶ä¸€å±‚
original = [[1, 2], [3, 4]]
shallow = copy.copy(original)
shallow[0][0] = 999
print(original)  # [[999, 2], [3, 4]] åŸåˆ—è¡¨è¢«ä¿®æ”¹äº†ï¼

# æ·±æ‹·è´ï¼šå®Œå…¨ç‹¬ç«‹å¤åˆ¶
original = [[1, 2], [3, 4]]
deep = copy.deepcopy(original)
deep[0][0] = 999
print(original)  # [[1, 2], [3, 4]] åŸåˆ—è¡¨æœªè¢«ä¿®æ”¹
```

åœ¨æ•°æ®å¢å¼ºä¸­çš„åº”ç”¨ï¼š

```python
import numpy as np

def bad_augment(images):
    """æµ…æ‹·è´å¯¼è‡´åŸæ•°æ®è¢«ä¿®æ”¹"""
    batch = images.copy()  # æµ…æ‹·è´
    batch[:, 0] = 0  # è®¾ç½®ç¬¬ä¸€åˆ—ä¸º 0
    return batch

images = np.random.randn(32, 3, 224, 224)
augmented = bad_augment(images)
# å¦‚æœå®é™…å·¥ä½œä¸­éœ€è¦åŸæ•°æ®ï¼Œè¿™ä¼šå¯¼è‡´é—®é¢˜
```

**é¿å… numpy â†’ python åˆ—è¡¨å¤§é‡è½¬æ¢**

```python
# âŒ ä½æ•ˆï¼šè½¬æ¢ä¸º Python åˆ—è¡¨
import numpy as np
data = np.random.randn(1000000)
python_list = data.tolist()  # è½¬æ¢ï¼Œå¾ˆæ…¢
for x in python_list:
    process(x)

# âœ… é«˜æ•ˆï¼šç›´æ¥è¿­ä»£ numpy
for x in data:
    process(x)

# âœ… æ›´é«˜æ•ˆï¼šå‘é‡åŒ–æ“ä½œ
result = np.vectorize(process)(data)
```

**ä½¿ç”¨ç”Ÿæˆå™¨æ›¿ä»£åˆ—è¡¨**

```python
# âŒ ä½æ•ˆï¼šä¸€æ¬¡æ€§åŠ è½½æ•´ä¸ªæ•°æ®é›†
def load_images_bad():
    images = []
    for file in file_list:
        images.append(load_image(file))
    return images  # è¿”å›å¤§åˆ—è¡¨ï¼Œå ç”¨å¤§é‡å†…å­˜

# âœ… é«˜æ•ˆï¼šå»¶è¿ŸåŠ è½½
def load_images_good():
    for file in file_list:
        yield load_image(file)  # ç”¨ç”Ÿæˆå™¨ï¼Œå†…å­˜é«˜æ•ˆ
```

### 5.2 åŠ é€ŸæŠ€å·§

**å‘é‡åŒ–æ“ä½œ**

```python
import numpy as np
import time

# âŒ å¾ªç¯ç‰ˆæœ¬ï¼šæ…¢
def slow_sum(arr):
    total = 0
    for x in arr:
        total += x
    return total

# âœ… å‘é‡åŒ–ç‰ˆæœ¬ï¼šå¿«
def fast_sum(arr):
    return np.sum(arr)

arr = np.random.randn(10**7)

start = time.time()
slow_sum(arr)
print(f"å¾ªç¯ç‰ˆæœ¬è€—æ—¶: {time.time()-start:.4f}s")  # ~0.5s

start = time.time()
fast_sum(arr)
print(f"å‘é‡åŒ–ç‰ˆæœ¬è€—æ—¶: {time.time()-start:.4f}s")  # ~0.001s
```

**NumPy çš„å¹¿æ’­ä¼˜åŒ–**

```python
import numpy as np

# å¹¿æ’­è‡ªåŠ¨æ‰©å±•æ•°ç»„ç»´åº¦ï¼Œé¿å…æ˜¾å¼å¾ªç¯
a = np.random.randn(1000, 1)     # (1000, 1)
b = np.random.randn(1, 100)      # (1, 100)

# è‡ªåŠ¨å¹¿æ’­åˆ° (1000, 100)
result = a + b  # é«˜æ•ˆã€ç®€æ´

# ç­‰ä»·çš„ä½æ•ˆå†™æ³•ï¼š
result_slow = np.zeros((1000, 100))
for i in range(1000):
    for j in range(100):
        result_slow[i, j] = a[i, 0] + b[0, j]
```

**Memory Pinningï¼ˆåŠ é€Ÿ GPU å¤åˆ¶ï¼‰**

```python
import torch

# âŒ æ™®é€šå†…å­˜ â†’ GPUï¼šæ¶‰åŠ DMA è½¬ç§»
data = torch.randn(1000, 1000)  # CPU å†…å­˜
gpu_data = data.cuda()  # å¤åˆ¶åˆ° GPUï¼ˆè¾ƒæ…¢ï¼‰

# âœ… é”å®šå†…å­˜ â†’ GPUï¼šæ›´å¿«
pinned_data = torch.randn(1000, 1000, pin_memory=True)
gpu_data = pinned_data.cuda()  # å¤åˆ¶æ›´å¿«ï¼ˆDMA ä¼˜åŒ–ï¼‰

# DataLoader ä¸­ä½¿ç”¨ pin_memory
from torch.utils.data import DataLoader
loader = DataLoader(dataset, pin_memory=True)  # åŠ é€Ÿæ•°æ®è½¬ç§»
```

**é«˜æ•ˆæ–‡ä»¶ IOï¼ˆmmapï¼‰**

```python
import numpy as np

# âŒ æ™®é€šæ–¹å¼ï¼šä¸€æ¬¡æ€§åŠ è½½
large_data = np.load('huge_file.npy')  # å ç”¨å¤§é‡å†…å­˜

# âœ… mmap æ–¹å¼ï¼šè™šæ‹Ÿæ˜ å°„ï¼ŒæŒ‰éœ€åŠ è½½
large_data = np.load('huge_file.npy', mmap_mode='r')
print(large_data[0:100])  # åªåŠ è½½å‰ 100 è¡Œåˆ°å†…å­˜
```

### 5.3 ä»£ç å‰–æï¼ˆprofilerï¼‰

**timeit**

```python
import timeit

def function_to_profile():
    return sum(range(1000))

# æµ‹é‡æ‰§è¡Œæ—¶é—´
time_taken = timeit.timeit(function_to_profile, number=100000)
print(f"å¹³å‡æ—¶é—´: {time_taken/100000*1e6:.2f} Î¼s")
```

**cProfile**

```python
import cProfile

def slow_function():
    total = 0
    for i in range(10**6):
        total += i
    return total

# åˆ†æå‡½æ•°æ€§èƒ½
cProfile.run('slow_function()')
# è¾“å‡ºæ¯ä¸ªå‡½æ•°çš„è°ƒç”¨æ¬¡æ•°ã€æ‰§è¡Œæ—¶é—´ç­‰
```

**PyTorch çš„ profiler**

```python
import torch
from torch.profiler import profile, record_function

# åˆ†ææ¨¡å‹å‰å‘ä¼ æ’­
model = YourModel()
x = torch.randn(1, 3, 224, 224)

with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA]) as prof:
    with record_function("forward"):
        output = model(x)

print(prof.key_averages().table(sort_by="cpu_time_total", row_limit=10))
```

**ğŸ’¡ å¯¹ AI çš„é‡è¦æ€§**ï¼š

è®­ç»ƒé€Ÿåº¦æå‡ 20%â€“50% æ˜¯å¸¸è§çš„æ”¶ç›Šã€‚é€šè¿‡åˆ†æï¼Œä½ èƒ½å‘ç°çœŸæ­£çš„æ€§èƒ½ç“¶é¢ˆã€‚

---

## 6. Python è®¾è®¡æ¨¡å¼ï¼ˆå†™å¯ç»´æŠ¤ AI ä»£ç çš„å…³é”®ï¼‰

### 6.1 å·¥å‚æ¨¡å¼

ç”¨å·¥å‚å‡½æ•°/ç±»æ¥åˆ›å»ºå¯¹è±¡ï¼Œé¿å…ç¡¬ç¼–ç ã€‚

```python
# âŒ ç¡¬ç¼–ç åˆ›å»ºä¸åŒæ¨¡å‹
def train(model_name):
    if model_name == "resnet":
        model = ResNet()
    elif model_name == "vgg":
        model = VGG()
    elif model_name == "mobilenet":
        model = MobileNet()
    return model

# âœ… å·¥å‚æ¨¡å¼
class ModelFactory:
    models = {
        "resnet": ResNet,
        "vgg": VGG,
        "mobilenet": MobileNet,
    }
    
    @classmethod
    def create(cls, model_name):
        model_class = cls.models.get(model_name)
        if not model_class:
            raise ValueError(f"æœªçŸ¥æ¨¡å‹: {model_name}")
        return model_class()

# ä½¿ç”¨
model = ModelFactory.create("resnet")
```

**Dataset å·¥å‚**

```python
class DatasetFactory:
    datasets = {
        "imagenet": ImageNetDataset,
        "cifar10": CIFAR10Dataset,
        "coco": COCODataset,
    }
    
    @classmethod
    def create(cls, dataset_name, **kwargs):
        dataset_class = cls.datasets[dataset_name]
        return dataset_class(**kwargs)

# ä½¿ç”¨
dataset = DatasetFactory.create("cifar10", root="/data/cifar10")
```

### 6.2 ç­–ç•¥æ¨¡å¼

ä¸åŒçš„ç®—æ³•/ç­–ç•¥ç‹¬ç«‹å°è£…ï¼Œæ˜“äºåˆ‡æ¢ã€‚

```python
# å®šä¹‰ä¼˜åŒ–å™¨ç­–ç•¥
class OptimizerStrategy:
    def __call__(self, params, lr):
        raise NotImplementedError

class SGDStrategy(OptimizerStrategy):
    def __call__(self, params, lr):
        return torch.optim.SGD(params, lr=lr)

class AdamStrategy(OptimizerStrategy):
    def __call__(self, params, lr):
        return torch.optim.Adam(params, lr=lr)

class CosineAnnealingStrategy(OptimizerStrategy):
    """å­¦ä¹ ç‡ç­–ç•¥"""
    def __call__(self, optimizer, T_max):
        return torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max)

# ä½¿ç”¨ï¼šæ˜“äºåˆ‡æ¢ç­–ç•¥
class Trainer:
    def __init__(self, optimizer_strategy, scheduler_strategy):
        self.opt_strategy = optimizer_strategy
        self.sched_strategy = scheduler_strategy
    
    def setup(self, model, lr):
        optimizer = self.opt_strategy(model.parameters(), lr)
        scheduler = self.sched_strategy(optimizer, T_max=100)
        return optimizer, scheduler

# é…ç½®ä¸åŒç­–ç•¥
trainer = Trainer(AdamStrategy(), CosineAnnealingStrategy())
```

### 6.3 å•ä¾‹æ¨¡å¼

ç¡®ä¿å…¨å±€åªæœ‰ä¸€ä¸ªå®ä¾‹ï¼ˆå¦‚æ—¥å¿—ã€é…ç½®ï¼‰ã€‚

```python
class Logger:
    _instance = None
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance

# ä½¿ç”¨
logger1 = Logger()
logger2 = Logger()
print(logger1 is logger2)  # True

# æ›´ç®€æ´çš„å•ä¾‹ï¼šè£…é¥°å™¨
def singleton(cls):
    instances = {}
    def get_instance(*args, **kwargs):
        if cls not in instances:
            instances[cls] = cls(*args, **kwargs)
        return instances[cls]
    return get_instance

@singleton
class Config:
    def __init__(self):
        self.lr = 0.001

cfg1 = Config()
cfg2 = Config()
print(cfg1 is cfg2)  # True
```

**ğŸ’¡ å¯¹ AI çš„é‡è¦æ€§**ï¼š

å¤§é¡¹ç›®ï¼ˆCV / NLP / RLï¼‰å¿…é¡»ä¿è¯ä»£ç å¯æ‰©å±•æ€§ã€‚è®¾è®¡æ¨¡å¼è®©ä»£ç æ›´çµæ´»ã€æ˜“ç»´æŠ¤ã€‚

---

## 7. AI å·¥ç¨‹ä¸­çš„ Python å®æˆ˜èƒ½åŠ›

### 7.1 Dataset / DataLoader è‡ªå®šä¹‰

**è‡ªå®šä¹‰è¿­ä»£å™¨**

```python
import torch
from torch.utils.data import Dataset, DataLoader

class CustomDataset(Dataset):
    def __init__(self, file_list, transform=None):
        self.file_list = file_list
        self.transform = transform
    
    def __len__(self):
        return len(self.file_list)
    
    def __getitem__(self, idx):
        # å»¶è¿ŸåŠ è½½ï¼šåªåœ¨éœ€è¦æ—¶åŠ è½½å›¾åƒ
        image = load_image(self.file_list[idx])
        if self.transform:
            image = self.transform(image)
        return image

# ä½¿ç”¨
dataset = CustomDataset(file_list)
loader = DataLoader(dataset, batch_size=32, num_workers=4)
for images in loader:
    # å¤šè¿›ç¨‹åŠ è½½æ•°æ®
    pass
```

**å¤šè¿›ç¨‹åŠ è½½**

```python
# num_workers > 0 ä¼šå¯ç”¨å¤šè¿›ç¨‹
loader = DataLoader(
    dataset,
    batch_size=32,
    num_workers=4,      # 4 ä¸ªè¿›ç¨‹
    pin_memory=True,    # é”å®šå†…å­˜åŠ é€Ÿ GPU è½¬ç§»
    prefetch_factor=2,  # é¢„åŠ è½½å› å­
)

# æ¯ä¸ªè¿›ç¨‹ç‹¬ç«‹è°ƒç”¨ __getitem__
```

**åŠ¨æ€æ•°æ®å¢å¼º**

```python
from torchvision import transforms

# å®šä¹‰å¢å¼ºç­–ç•¥
transform = transforms.Compose([
    transforms.RandomHorizontalFlip(),
    transforms.ColorJitter(brightness=0.2),
    transforms.RandomRotation(10),
    transforms.ToTensor(),
])

class AugmentedDataset(Dataset):
    def __init__(self, images, labels):
        self.images = images
        self.labels = labels
        self.transform = transform
    
    def __getitem__(self, idx):
        image = self.images[idx]
        # æ¯æ¬¡è¿”å›ä¸åŒçš„å¢å¼ºç‰ˆæœ¬
        image = self.transform(image)
        return image, self.labels[idx]
```

### 7.2 è®­ç»ƒæ¡†æ¶å°è£…

**è£…é¥°å™¨è®°å½•è®­ç»ƒè¿‡ç¨‹**

```python
from functools import wraps
import logging

def log_training(func):
    """è®°å½•è®­ç»ƒè¿‡ç¨‹"""
    @wraps(func)
    def wrapper(self, *args, **kwargs):
        logging.info(f"ã€å¼€å§‹ã€‘{func.__name__}")
        result = func(self, *args, **kwargs)
        logging.info(f"ã€å®Œæˆã€‘{func.__name__}")
        return result
    return wrapper

class Trainer:
    @log_training
    def train_epoch(self):
        # è®­ç»ƒä»£ç 
        pass
    
    @log_training
    def validate(self):
        # éªŒè¯ä»£ç 
        pass
```

**å¼‚æ­¥æ•°æ®é¢„å¤„ç†**

```python
from concurrent.futures import ThreadPoolExecutor

class AsyncDataLoader:
    def __init__(self, dataset, batch_size=32, num_workers=4):
        self.dataset = dataset
        self.batch_size = batch_size
        self.executor = ThreadPoolExecutor(max_workers=num_workers)
    
    def __iter__(self):
        for i in range(0, len(self.dataset), self.batch_size):
            # æäº¤é¢„å¤„ç†ä»»åŠ¡
            future = self.executor.submit(
                self._load_batch,
                i, i + self.batch_size
            )
            yield future.result()
    
    def _load_batch(self, start, end):
        batch = [self.dataset[i] for i in range(start, end)]
        return batch
```

**æ¨¡å‹è‡ªåŠ¨ä¿å­˜/æ¢å¤**

```python
import torch
import os

class CheckpointManager:
    def __init__(self, save_dir):
        self.save_dir = save_dir
        os.makedirs(save_dir, exist_ok=True)
    
    def save(self, model, optimizer, epoch, metrics):
        path = os.path.join(self.save_dir, f"checkpoint_epoch_{epoch}.pt")
        torch.save({
            'model': model.state_dict(),
            'optimizer': optimizer.state_dict(),
            'epoch': epoch,
            'metrics': metrics,
        }, path)
        print(f"ä¿å­˜æ£€æŸ¥ç‚¹: {path}")
    
    def load(self, model, optimizer, path):
        checkpoint = torch.load(path)
        model.load_state_dict(checkpoint['model'])
        optimizer.load_state_dict(checkpoint['optimizer'])
        epoch = checkpoint['epoch']
        print(f"åŠ è½½æ£€æŸ¥ç‚¹: {path}ï¼Œæ¢å¤åˆ° epoch {epoch}")
        return epoch

# ä½¿ç”¨
ckpt_mgr = CheckpointManager('./checkpoints')
ckpt_mgr.save(model, optimizer, epoch=10, metrics={'acc': 0.95})
```

### 7.3 æ¨¡å‹éƒ¨ç½²

**TorchScript**

```python
import torch

class SimpleModel(torch.nn.Module):
    def forward(self, x):
        return x * 2

model = SimpleModel()
# è½¬ä¸º TorchScriptï¼ˆå¯è„±ç¦» Python ç¯å¢ƒè¿è¡Œï¼‰
scripted = torch.jit.script(model)
scripted.save('model.pt')

# åŠ è½½å¹¶æ¨ç†
loaded_model = torch.jit.load('model.pt')
output = loaded_model(torch.randn(1, 10))
```

**å¤šè¿›ç¨‹æ¨ç†æœåŠ¡**

```python
from multiprocessing import Process, Queue
import torch

class InferenceWorker:
    def __init__(self, model_path, input_queue, output_queue):
        self.model = torch.jit.load(model_path)
        self.input_queue = input_queue
        self.output_queue = output_queue
    
    def run(self):
        while True:
            request_id, input_data = self.input_queue.get()
            output = self.model(input_data)
            self.output_queue.put((request_id, output))

# å¯åŠ¨å¤šä¸ªæ¨ç†è¿›ç¨‹
input_q = Queue()
output_q = Queue()
workers = [
    InferenceWorker('model.pt', input_q, output_q)
    for _ in range(4)
]
for w in workers:
    p = Process(target=w.run)
    p.start()

# æäº¤æ¨ç†è¯·æ±‚
input_q.put(('req_1', torch.randn(1, 3, 224, 224)))
request_id, output = output_q.get()
```

**å¼‚æ­¥ API æ¨ç†æœåŠ¡**

```python
import asyncio
import torch
from aiohttp import web

class AsyncInferenceServer:
    def __init__(self, model_path):
        self.model = torch.jit.load(model_path)
    
    async def infer(self, request):
        data = await request.json()
        input_tensor = torch.tensor(data['input'])
        
        # å¼‚æ­¥æ¨ç†ï¼ˆä¸é˜»å¡å…¶ä»–è¯·æ±‚ï¼‰
        output = await asyncio.to_thread(
            self._sync_infer,
            input_tensor
        )
        
        return web.json_response({'output': output.tolist()})
    
    def _sync_infer(self, x):
        return self.model(x)

# å¯åŠ¨æœåŠ¡
app = web.Application()
server = AsyncInferenceServer('model.pt')
app.router.add_post('/infer', server.infer)
web.run_app(app, port=8080)

# å®¢æˆ·ç«¯è¯·æ±‚
# curl -X POST http://localhost:8080/infer -d '{"input": [1, 2, 3]}'
```

---

## æ€»ç»“

| ä¸»é¢˜ | æ ¸å¿ƒæ¦‚å¿µ | AI åº”ç”¨åœºæ™¯ |
|------|--------|----------|
| **æ‰§è¡Œæ¨¡å‹** | GILã€å¼•ç”¨è®¡æ•° | ç†è§£ä¸ºä»€ä¹ˆ DataLoader ç”¨å¤šè¿›ç¨‹ |
| **è¿­ä»£å™¨/ç”Ÿæˆå™¨** | yieldã€å»¶è¿Ÿè®¡ç®— | é«˜æ•ˆåŠ è½½å¤§æ•°æ®é›† |
| **è£…é¥°å™¨** | é—­åŒ…ã€å…ƒç¼–ç¨‹ | è®­ç»ƒæ—¥å¿—ã€æ€§èƒ½ç›‘æ§ã€è‡ªåŠ¨é‡è¯• |
| **å¹¶è¡Œ/å¹¶å‘** | å¤šè¿›ç¨‹ã€å¼‚æ­¥ | å¤šæ ¸æ•°æ®åŠ è½½ã€å¼‚æ­¥æ¨ç†æœåŠ¡ |
| **æ€§èƒ½ä¼˜åŒ–** | å‘é‡åŒ–ã€å†…å­˜ç®¡ç† | åŠ é€Ÿè®­ç»ƒã€å‡å°‘æ˜¾å­˜å ç”¨ |
| **è®¾è®¡æ¨¡å¼** | å·¥å‚ã€ç­–ç•¥ã€å•ä¾‹ | å¤§é¡¹ç›®ä»£ç ç»“æ„ã€æ˜“æ‰©å±•æ€§ |
| **å·¥ç¨‹å®æˆ˜** | Datasetã€è®­ç»ƒæ¡†æ¶ã€éƒ¨ç½² | å®Œæ•´çš„ AI å¼€å‘æµç¨‹ |

æŒæ¡è¿™äº›çŸ¥è¯†ï¼Œä½ å°±èƒ½å†™å‡º**é«˜æ•ˆã€å¯ç»´æŠ¤ã€æ˜“æ‰©å±•**çš„ AI ä»£ç ï¼































