# 生成对抗网络GAN

## 一、生成对抗网络基本原理

### GAN的概念及背景
- **定义**：GAN (Generative Adversarial Networks)，中文名称为生成式对抗网络，是 Ian Goodfellow 等在2014 年提出的一种生成式模型
- **基本思想**：源自博弈论的二人零和博弈，由一个生成器和一个判别器构成，通过对抗学习的方式来训练，目的是估计数据样本的潜在分布并生成新的数据样本

- **起源与发展**：
  - 2001年：Tony Jebara 在毕业论文中以最大熵形式将判别模型与生成模型结合起来联合学习
  - 2007年：Zhuowen Tu 提出将基于boosting分类器的判别模型与基于采样的生成模型相结合，来产生出服从真实分布的样本
  - 2012年：Jun Zhu 将最大间隔机制与贝叶斯模型相结合进行产生式模型的学习
  - 2014年：Ian Goodfellow 等人提出生成式对抗网络

- **GAN提出的背景**：
  - 人工智能的热潮
  - 生成式模型的积累
  - 神经网络的深化
  - 对抗思想的成功

### GAN的基本原理
- **核心思想**：来源于博弈论的纳什均衡，设定参与游戏双方分别为一个生成器 (Generator) 和一个判别器 (Discriminator)
  - 生成器的目的：尽量去学习真实的数据分布
  - 判别器的目的：尽量正确判别输入数据是来自真实数据还是来自生成器
  - 学习优化过程：寻找二者之间的一个纳什均衡

- **网络结构**：
  - 交替训练生成器和判别器这两个网络，目的是驱使生成样本与真实样本无法区分
  - 生成器G和判别器D形成一个动态的"对抗或博弈"过程
  - 最理想的结果是D(G(z))与真实数据的表现D(x)相同，此时G和D达到最优

- **GAN结构的误差反馈**：
  - 生成器G：接收一个随机噪声z，生成图片G(z)
  - 判别器D：判别一张图片是不是"真实的"，输出D(x)代表x为真实图片的概率（1表示真实，0表示假）
  - 原生GAN中生成器和判别器都是用全连接网络实现

### GAN的训练

#### 判别器损失函数
- **表达式**：
  $J^{(D)} = \frac{1}{2} \mathbb{E}_{x \sim p_{data}} [\log D(x)] + \frac{1}{2} \mathbb{E}_{z \sim p_z} [\log(1 - D(G(z)))]$
  
- **说明**：
  - $\theta_D$ 和 $\theta_G$ 分别是判别器和生成器网络的参数
  - $p_{data}$ 表示真实数据的分布，x是来自 $p_{data}$ 的样本
  - $p_z$ 是生成器的分布，z是来自 $p_z$ 的样本
  - G是生成器网络，D是判别器网络
  - 判别器被训练为基于两个小批量数据的二元分类器（带有sigmoid输出）
  - 一个小批量来自真实数据（标记为1），另一个来自生成器（标记为0）

#### 生成器损失函数
- **原始GAN的生成器损失函数**（启发式、非饱和损失函数）：
  $J^{(G)} = \frac{1}{2} \mathbb{E}_{z \sim p_z} [\log D(G(z))]$
  
- **说明**：
  - 生成器的梯度仅取决于判别器损失函数的第二项
  - 与极大极小函数相反，目标使用 $\log D(G(z))$ 而不是 $\log(1 - D(G(z)))$
  - 优点：生成器在开始训练过程中获得强梯度信息，有助于快速改进
  - 不依赖于真实数据，有助于避免生成器中的过拟合问题

#### GAN网络训练方法
- **步骤**：
  1. 从真实数据集 $p_{data}$ 中抽出一小批m个样本
  2. 从生成器 $p_z$ 中抽取一小批m个样本
  3. 通过最小化判别器损失函数来学习判别器
  4. 从生成器 $p_z$ 中对一小批样本采样
  5. 通过最小化生成器损失函数来学习生成器

- **训练策略**：
  - 采用交替优化方法：先固定生成器 G，优化判别器 D；然后固定判别器 D，优化生成器 G
  - 当且仅当 $D^*(x) = \frac{p_{data}(x)}{p_{data}(x) + p_g(x)}$ 时达到全局最优解，完成一轮训练
  - 在同一轮参数更新中，一般对 D 的参数更新 k 次再对 G 的参数更新 1 次（优先提高判别器的性能）

### GAN的应用
- **直接应用**：建模，生成与真实数据分布一致的数据样本
- **解决的问题**：标注数据不足时的学习问题
- **应用领域**：
  - 图像和视觉领域：生成与真实数据分布一致的图像，如将低清模糊图像变换为高清图像
  - 语音和语言领域
  - 其它领域

### GAN的衍生模型
- **DCGAN**：深度卷积生成对抗网络，提出能稳定训练的网络结构
- **InfoGAN**：信息最大化生成对抗网络，通过隐变量控制语义变化
- **CGAN**：条件生成对抗网络，为防止训练崩塌将前置条件加入生成器的输入数据
- **EBGAN**：基于能量的生成对抗网络，从能量模型角度给出解释
- **Improved GAN**：改进生成式对抗网络，提出五条经验：
  a. 特征匹配（feature matching）
  b. 最小批量判断（minibatch discrimination）
  c. 历史平均（historical averaging）
  d. 单边标签平滑（one-sided label smoothing）
  e. 虚拟批量正则（virtual batch normalization）

### GAN的优点和意义
- **对生成式模型的贡献**：
  - 有效解决可建立自然性解释的数据的生成难题
  - 将两个神经网络的对抗作为训练准则，可以使用反向传播进行训练
  - 大大改善生成式模型的训练难度和训练效率
  - 生成的样本易于人类理解
- **对半监督学习的启发**：为半监督学习提供了新的思路

### GAN的缺陷
- **优化问题**：优化过程存在不稳定性，容易陷入鞍点或局部极值点，即"崩溃模式现象"
- **可解释性差**：作为以神经网络为基础的生成式模型，存在神经网络的一般性缺陷
- **通用性问题**：模型需要提高通用性，尤其在处理大规模数据的时候

## 二、深度卷积生成对抗网络

### DCGAN概述
- **定义**：深度卷积生成对抗网络（Deep Convolutional GAN，DCGAN）
- **解决的问题**：GAN网络具有训练不稳定、生成过程不可控、不具备可解释性等缺点
- **改进**：在生成模型和判别模型中添加了卷积神经网络，使得生成性能有了很大提高
- **参考价值**：许多生成式网络的改进都是参照DCGAN进行了性能的优化和改进

### DCGAN的改进
- **主要改进**：
  1. 生成器和判别者都舍弃了CNN的池化层，判别器保留CNN的整体架构，生成器将卷积层替换成反卷积层
  2. 在判别器和生成器中每一层之后都使用了BN层，有助于处理初始化不良导致的训练问题，加速模型训练，提升训练稳定性
  3. 利用1*1卷积层替换到所有的全连接层
  4. 在生成器中除输出层使用Tanh激活函数，其余层全部使用ReLU激活函数
  5. 在判别器所有层都使用LeakyReLU激活函数，防止梯度稀疏

### DCGAN生成器
- **架构特点**：
  - 从全卷积网络（FCN）借鉴，不包含任何池化和反池化层
  - 使用反卷积来增加表示空间的大小
  - 将一个100维的噪音向量扩展成64*64*3的矩阵输出，采用微步卷积的方式

### 反卷积
- **定义**：上采样和反卷积是同一个概念，目的是将经过特征提取以后缩小的矩阵扩大到一定的大小

### DCGAN判别器
- **架构特点**：
  - 使用卷积来挤压分类任务的表示空间大小
  - 结构与生成器不同，使用卷积层而非反卷积层

### DCGAN的架构
- **网络结构特点**：
  - 在卷积核、反卷积核中使用大于1（通常为2）的步幅
  - 除了判别器的第一层和生成器的最后一层外，批量归一化用于其他所有层
  - 确保DCGAN学习正确的数据分布规模及其平均值

- **优化器选择**：
  - 使用Adam优化器更新参数而不是具有动量的SGD优化器

### 结果展示
- **应用**：使用ImageNet的人脸数据集进行无监督训练
- **效果**：生成器能够生成较为逼真的人脸图像

## 三、超分辨率生成对抗网络

### SRGAN概述
- **定义**：超分辨率生成对抗网络（Super-Resolution GAN，SRGAN），2016年提出
- **功能**：生成器网络的输入是低分辨率（LR）图像，输出是对应的高分辨率（HR）图像
- **创新点**：将感知损失函数用于生成器，由两部分组成："内容损失"（局部）和"对抗性损失"（全局）
- **感知损失函数**：$l_{SR} = l_{SR}^{Con} + l_{SR}^{Adv}$

### 生成器的内容损失
- **问题**：使用像素空间均方误差（MSE）损失函数能够通过抑制高频内容来平滑图像，但会导致感知上不满意的问题
- **解决方案**：使用感知相似性驱动的特征空间内容损失函数：
  $l_{Con}^{SR} = \frac{1}{WH} \sum_{x=1}^{W} \sum_{y=1}^{H} \|\phi(I_{HR}^y) - \phi(G_{\theta_g}(I_{LR}^y))\|_2^2$
  
- **说明**：
  - $I_{LR}$ 和 $I_{HR}$ 是LR和HR图像
  - $\phi(\cdot)$ 是由VGGNet-19的卷积层产生的输出特征图
  - W和H分别是特征图的长和宽
  - 内容损失函数是计算$I_{LR}$生成图像的输出特征图与真实高分辨率图像$I_{HR}$的特征图之间的欧式距离

### 生成器的对抗性损失
- **定义**：与原始GAN中的启发式损失函数相同：
  $l_{Adv}^{SR} = \log(D_{\theta_d}(G_{\theta_g}(I_{LR})))$
  
- **说明**：
  - $D_{\theta_d}(G_{\theta_g}(I_{LR}))$ 是生成器产生图像的判别概率
  - $G_{\theta_g}(I_{LR})$ 是高分辨率生成图像

### 生成器的总损失
- **定义**：感知损失函数是内容损失函数和对抗损失函数的加权总和：
  $l_{SR} = l_{SR}^{Con} + 10^{-3} l_{SR}^{Adv} = \frac{1}{WH} \sum_{x=1}^{W} \sum_{y=1}^{H} \|\phi(I_{HR}^y) - \phi(G_{\theta_g}(I_{LR}^y))\|_2^2 - 10^{-3} \log(D_{\theta_d}(G_{\theta_g}(I_{LR}^y)))$
  
- **说明**：
  - 第一项是内容损失，第二项是对抗损失
  - 权重$10^{-3}$用于平衡两项损失

### SRGAN的生成器网络
- **架构特点**：
  - 灵感来自深度残差网络和DCGAN的架构
  - 所有层中都使用了LeakyReLU激活函数
  - 除了第一卷积层外，在其它所有卷积层之后都使用批量归一化

### 判别器损失
- **定义**：交叉熵损失函数，将其训练为具有sigmoid输出的二元分类器：
  $J^{(D)} = \mathbb{E}_{x \sim p_{data}} [\log D(x)] + \mathbb{E}_{z \sim p_z} [\log(1 - D(G(z)))]$
  
- **说明**：
  - $\theta_D$ 和 $\theta_G$ 分别是判别器和生成器网络的参数
  - $p_{data}$ 表示真实数据的分布，x是来自 $p_{data}$ 的样本
  - $p_z$ 是生成器的分布，z是来自 $p_z$ 的样本
  - G是生成器网络，D()是判别器网络

### SRGAN的判别器网络
- **架构特点**：
  - 灵感来自DCGAN的架构，没有池化层
  - 由8个卷积层组成，卷积核大小为3*3，步长1和2交替出现
  - 跟着两个全连接层以及一个sigmoid函数来执行二元分类

### SRGAN总结
- **特点**：
  1. 提出感知域的损失函数用于在特征空间（代替像素空间）中优化超分辨率模型
  2. 生成对抗网络通过鼓励网络生成一些更接近于自然图像的方法来提升超分辨率的质量
  3. 语义图像先验信息用于进一步改善恢复的纹理细节
- **局限性**：得到的图像和GT图像仍有较大的差距

### ESRGAN
- **定义**：Enhanced Super-Resolution Generative Adversarial Networks，发表于ECCV2018，是基于SRGAN改进而来
- **改进方面**：
  1. 改进了网络结构，去掉了所有BN层，引入残差密集块(Residual-in-Residual Dense Block, RRDB)
  2. 改进了对抗损失
  3. 改进了感知损失，使用激活前的VGG特征来计算感知损失

- **效果对比**：
  - 在锐度和边缘信息上优于SRGAN，且去除了"伪影"
  - 从PI和PMSE两个指标来看，是当时超分辨率复原任务中最佳水平

#### 对Residual Blocks的改进
1. **去除掉所有的BN层**：
   - BN层在训练时使用一个batch数据的均值和方差，在测试时使用测试集上的统计量
   - 当训练集和测试集的统计量差异大时，BN层会生成不好的伪影，限制模型泛化能力
   - 去掉BN层能提高GAN模型的泛化能力，减少计算复杂度和内存占用

2. **提出残差密集块（RRDB）**：
   - 结合多层残差网络和密集连接
   - 更好提升恢复得到的纹理

#### 相对判别器
- **改进**：基于 Relativistic GAN 改进了判别器
- **变化**：判别器D估计真实图像相对来说比假图像更逼真的概率
- **判别器损失函数**：$L = \mathbb{E}_{x_r \sim p_{data}} [\log(D(x_r - x_f))] + \mathbb{E}_{x_f \sim p_g} [\log(1 - D(x_f - x_r))]$
- **生成器对抗损失函数**：$L = \mathbb{E}_{x_f \sim p_g} [\log(D(x_f - x_r))] + \mathbb{E}_{x_r \sim p_{data}} [\log(1 - D(x_r - x_f))]$
  
- **说明**：$x_f = G(x_i)$，$x_i$代表LR图像输入

#### 生成器的感知域损失
- **改进**：使用激活前的VGG特征来计算感知损失
- **优势**：
  - 避免激活后的特征稀疏问题，提供更强的监督
  - 避免重建图像与GT的亮度不一致问题

#### 网络插值
- **目的**：移除生成器在基于GAN的方法带来的令人不愉快的噪声，同时获得很好的感知质量
- **方法**：
  1. 基于PSNR方法训练得到网络$G_{PSNR}$
  2. 对其用GAN网络进行微调得到$G_{GAN}$
  3. 对这两个网络参数进行插值：$G_{INTERP} = (1-\alpha) \times G_{PSNR} + \alpha \times G_{GAN}$

### ESRGAN结论
1. 去掉BN：并没有降低网络性能，节省计算资源和内存占用，减少伪影
2. 使用激活前的特征：得到的图像亮度更准确，产生更尖锐的边缘和更丰富的细节
3. RaGAN：产生更尖锐的边缘和更丰富的细节
4. RDDB：更好提升恢复得到的纹理，去除噪声

## 四、风格迁移网络

### 风格迁移网络概述
- **起源**：始于2015年Gates的论文"Image Style Transfer Using Convolutional Neural Networks"
- **功能**：由一张内容图片和一张风格图片进行融合，得到经风格渲染之后的合成图片

### 网络架构
- 使用经典的VGG19网络，分为5个block：
  - 每个block由若干卷积层及之后的池化层组成
  - 第一个block有2层卷积（conv1_1和conv1_2）
  - 第二个block也是2层卷积
  - 之后的3个block都是4层卷积
  - 最后是两个全连接层（FC1和FC2）和一个softmax层
- 风格迁移不需要全连接层和softmax层

### 风格迁移流程
1. 内容图片和风格图片分别经过VGG19的5个block
2. 提取并存储内容图片和风格图片的特征
3. 添加随机白噪声的噪声图像通过判别器网络
4. 计算风格损失和内容损失
5. 总损失是内容损失和风格损失的线性组合
6. 使用误差反向传播计算相对于像素的梯度，更新噪声图像

### 特征提取对比
- **内容图片**：经过VGG19网络，在每层得到feature map，记为$F_{p}^l$，保留原图信息
- **风格图片**：经过VGG19网络，提取风格特征，基本看不出原图样貌
- **合成图片**：经过VGG19网络，得到特征记为$F_{x}^l$

### 生成器内容损失
- **定义**：只取conv4_2层的特征，计算内容图片特征和合成图片特征之间的欧式距离：
  $L_{content}(p,x,l) = \frac{1}{2} \sum_{i,j} (F_{p,ij}^l - F_{x,ij}^l)^2$
  
- **说明**：
  - $p$ 表示内容图片，$x$ 表示希望生成的新图片
  - $l$ 表示第l层的卷积网络
  - $F_{p,ij}^l$ 表示第l层的第i个滤波器在位置j上的激活响应
  - $F_{x,ij}^l$ 表示合成图片的相应激活响应

### 生成器风格损失
- **Gram矩阵定义**：$G_{ij}^l = \sum_k F_{ik}^l F_{jk}^l$
  
- **风格损失定义**：
  $E_{ij}^l = \frac{1}{N_l^2 M_l^2} (G_{ij}^l - A_{ij}^l)^2$
  $L_{style}(a,x) = \sum_l \omega_l E_{ij}^l$
  
- **说明**：
  - $F$表示特征图被展开成1-D的向量
  - $k$表示某个特征图被展开成向量后的位置索引
  - $i, j$表示同层内的不同特征图的通道索引
  - $l$表示当前所在的隐层索引
  - $G_{ij}^l \in \mathbb{R}^{N_l \times N_l}$，其中$N_l$是第l层的特征图数量

### 生成器总损失
- **定义**：生成器总损失为内容损失和风格损失的线性和：
  $L_{total}(p,a,x) = \alpha L_{content}(p,x) + \beta L_{style}(a,x)$
  
- **说明**：
  - 改变$\alpha$和$\beta$的比重可以调整内容和风格的占比
  - 内容损失实际上只用了第四个block提取的特征
  - 风格损失时，5个block提取的特征都用来计算，增加风格的多样性

## 五、辅助分类器生成式对抗网络

### CGAN和ACGAN概述
- **原始GAN的局限性**：功能简单，只能输入噪声数据输出伪造图片，无法控制生成图像的模式
- **CGAN**：2014年提出，通过给GAN的生成器添加辅助信息（如类别标签），实现生成图片类别的精准控制
- **ACGAN**：2016年提出，在CGAN基础上进一步拓展，采用辅助分类器，使GAN的生成器具有图像分类功能

### CGAN
- **条件生成**：使用类别标签作为辅助信息，指导数据生成过程
- **实现方式**：
  - 标签信息和噪声数据进行拼接后送入生成器
  - 标签信息和真实图片拼接后送入判别器
  - 生成图像单独送入判别器

- **损失函数**：
  $\min_G \max_V V(D,G) = \mathbb{E}_{x \sim p_{data}} [\log D(x|y)] + \mathbb{E}_{z \sim p_z} [\log(1 - D(G(z|y)))]$
  
- **说明**：
  - y代表条件，可以是图片、类别标签等
  - G表示生成器，D表示判别器
  - x表示真实图像，z表示随机采样得到的噪声

### ACGAN
- **改进点**：
  1. 判别器功能扩展：判别真假以及类别区分
  2. 网络层改进：使用深层卷积网络而非全连接网络，提取更好的图片特征

- **损失函数**：
  - 真假判别损失：$L_s = \mathbb{E}_{x \sim p_{data}} [\log D_{\text{real}}(x)] + \mathbb{E}_{z \sim p_z} [\log(1 - D_{\text{fake}}(x))]$
  - 分类损失：$L_c = \mathbb{E}_{x \sim p_{data}} [\log C_{\text{real}}(x)] + \mathbb{E}_{z \sim p_z} [\log C_{\text{fake}}(x)]$
  
- **训练目标**：
  - 判别器D：最大化$L_c + L_s$
  - 生成器G：最大化$L_c - L_s$

- **网络结构**：
  - 生成器：输入包括class和noise两部分，进行拼接后生成图像
  - 判别器：输入为图片，输出为两部分（真假判断和分类）
  - 判别器的最后一层有两个并列的全连接层，分别得到这两部分的输出结果

### ACGAN实验效果
- 能够生成具有特定类别标签的高质量图像
- 在图像生成质量和类别控制上优于原始GAN和CGAN
