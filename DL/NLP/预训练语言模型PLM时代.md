# 预训练语言模型（PLM）时代（BERT → GPT）

1. 预训练模型的范式
	•	Masked Language Model（MLM：BERT）
	•	AutoRegressive LM（GPT）
	•	Next Sentence Prediction（NSP）
	•	Permutation LM（XLNet）
	•	Prefix LM（T5）

2. 经典模型架构
	•	BERT、RoBERTa
	•	GPT-2 / GPT-3
	•	T5
	•	ALBERT
	•	DistilBERT（模型压缩思想）
	•	ELECTRA（替换采样）

实践：
	•	HuggingFace Transformers
	•	复现文本分类 / 问答任务
	•	试着做 Prompt-based fine-tuning