# 大模型时代（LLM & SFT & RAG）

1. 大模型的训练范式

现代大模型主要由三步构成：

① 预训练（Pre-training）
	•	海量文本（网页、书籍、GitHub…）
		- **是什么**：给模型喂几万亿 token 的互联网文本，让它做“成语接龙”（预测下一个词）。
		- **解决什么问题**：让模型学习世界的通用知识（常识、物理规律、代码逻辑）和语言的语法语义，获得“基座能力”。
	•	自回归任务
		- **是什么**：Training objective，即 $P(w_t | w_{1:t-1})$。
		- **解决什么问题**：最简单有效的无监督学习方式，利用海量无标注数据。
	•	规模与压缩技术（分布式训练、并行策略）
		- **是什么**：数据并行、模型并行（张量并行、流水线并行）。
		- **解决什么问题**：单张显卡根本装不下大模型，必须用成百上千张显卡协同训练。

② 指令微调（SFT）
	•	人工标注的 instruction 数据
		- **是什么**：高质量的“问题-答案”对。例如：“请把这句话翻译成中文” -> “翻译结果”。
		- **解决什么问题**：预训练模型只会续写文本（比如你问“美国首都是哪？”，它可能续写“中国首都是哪？”），SFT 教会模型“听懂指令”并按要求回答。
	•	Prompt Engineering 基础
		- **是什么**：设计更好的输入提示词来激发模型能力（如思维链 CoT）。
		- **解决什么问题**：不改变模型参数，仅通过改变输入就让模型表现更好。
	•	微调流程（LoRA / 知识编辑）
		- **是什么**：LoRA（低秩适应）是只训练模型中极小一部分参数（<1%）。
		- **解决什么问题**：全量微调太贵了，LoRA 让普通人也能用消费级显卡微调大模型。

③ 对齐技术（Alignment）
	•	RLHF（Reinforcement Learning with Human Feedback）
		- **是什么**：人类反馈强化学习。先训练一个奖励模型（Reward Model）模仿人类喜好，然后用强化学习（PPO）优化大模型。
		- **解决什么问题**：让模型不仅能回答，而且回答得“有用、无害、诚实”，符合人类价值观。
	•	DPO（Direct Preference Optimization）
		- **是什么**：直接偏好优化。跳过奖励模型，直接用偏好数据（A比B好）去优化模型。
		- **解决什么问题**：比 RLHF 更简单、更稳定，训练速度更快，效果通常也不错。
	•	ORPO / GRPO（2024–2025 新平替）
		- **是什么**：更新的对齐算法，进一步简化流程或提升特定能力（如推理）。
		- **解决什么问题**：追求更高效的对齐效果。
	•	评测（MMLU, MTBench）
		- **是什么**：大模型的“高考试卷”。MMLU 测知识，MTBench 测对话能力。
		- **解决什么问题**：量化评估模型聪明程度，方便横向对比。

2. 模型部署与推理优化
	•	Batching / KV Cache
		- **是什么**：
			- Batching：一次处理多个用户的请求。
			- KV Cache：缓存已经计算过的 Attention Key/Value 矩阵。
		- **解决什么问题**：大幅提升推理速度（吞吐量），避免每次生成新词都重新计算前面的内容。
	•	量化（AWQ，GPTQ，INT4）
		- **是什么**：把模型参数从高精度（FP16）变成低精度（INT4），比如把 16 位浮点数变成 4 位整数。
		- **解决什么问题**：显存占用直接砍到 1/3 或 1/4，让 7B 模型能在笔记本上跑，70B 模型能在单卡上跑。
	•	张量并行 / 管道并行
		- **是什么**：把模型切开放在不同卡上推。
		- **解决什么问题**：解决单卡显存不足以加载模型的问题。
	•	vLLM 推理引擎原理
		- **是什么**：目前最流行的开源推理框架，核心技术是 PagedAttention。
		- **解决什么问题**：像操作系统管理内存一样管理显存，极大地减少了显存碎片，吞吐量比 HuggingFace 原始实现高十几倍。
	•	Triton 编写自定义 kernel（进阶）
		- **是什么**：OpenAI 出的 GPU 编程语言，比 CUDA 简单。
		- **解决什么问题**：为了极致的性能，手写算子来榨干 GPU 性能。

⸻

3. RAG（Retrieval-Augmented Generation）增强大模型
	•	何时使用 RAG vs Fine-tuning
		- **是什么**：RAG 是考试带书（外挂知识库），Fine-tuning 是把书背下来（内化参数）。
		- **解决什么问题**：如果需要模型知道最新的新闻或企业内部私有数据，RAG 更合适（成本低、更新快）；如果需要模型学会特定的说话风格或领域术语，Fine-tuning 更合适。
	•	向量数据库（FAISS、Milvus）
		- **是什么**：专门存向量（Embedding）的数据库。
		- **解决什么问题**：在大规模知识库中快速找到和用户问题最相似的文档片段。
	•	文档切分策略（Chunking）
		- **是什么**：把长文档切成小块（Chunk）。
		- **解决什么问题**：模型上下文有限，不能把整本书塞进去，切块能保证检索的精准度。
	•	Retriever（BM25、Dense Retrieval）
		- **是什么**：检索器。BM25 靠关键词匹配，Dense Retrieval 靠语义向量匹配。
		- **解决什么问题**：决定了能搜到什么内容，直接影响回答质量。
	•	多模态 RAG（图像、表格）
		- **是什么**：不仅检索文本，还能检索图片和表格。
		- **解决什么问题**：处理包含图表的复杂文档（如财报、论文）。

实践：
	•	构建自己的企业知识库问答系统
	•	使用 LlamaIndex / LangChain 完整搭建 RAG pipeline
